{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1aXwfsXEusH9X2nwY2AwhJtAzgJqweH2Z",
      "authorship_tag": "ABX9TyNqcajUgrsNpBT1DDdiLA/a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farieu/data-analysis/blob/Pipeline/Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pipeline de Pré-Processamento"
      ],
      "metadata": {
        "id": "gWHf0Q9yxKiJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Imputação de bibliotecas"
      ],
      "metadata": {
        "id": "Lz7SZcN534Pc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, MultiLabelBinarizer, FunctionTransformer, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "QPXgzuIU36v4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/BackEnd/GoodReads_100k_books.csv')"
      ],
      "metadata": {
        "id": "kDhACpFQ3_J0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testando uma tentativa de Pipeline de pré-processamento, para codificar e utilizar o RandomForest."
      ],
      "metadata": {
        "id": "kWanUyPj4PpH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(subset=['title', 'desc', 'genre', 'bookformat'], inplace=True)\n",
        "numeric_features = ['pages', 'totalratings', 'reviews']\n",
        "categorical_features = ['author', 'bookformat', 'genre', 'title']\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor)\n",
        "])"
      ],
      "metadata": {
        "id": "m581V19-4UXX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplicando o pipeline e separando as variáveis independentes e a variável alvo."
      ],
      "metadata": {
        "id": "0uWBQICc4gOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=['rating', 'desc', 'isbn', 'isbn13', 'img', 'link'])\n",
        "y = df['rating']\n",
        "\n",
        "df_preprocessed = pipeline.fit_transform(X)\n",
        "print(X.shape)\n",
        "\n",
        "df_preprocessed_df = pd.DataFrame(df_preprocessed.toarray() if isinstance(df_preprocessed, np.ndarray) else df_preprocessed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ox7Z9FyKjACz",
        "outputId": "d0b18386-8588-4ddb-88f4-6b2d7d41aeba"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(84054, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separando conjunto de dados processado pelo pipeline em 80% treino e 20% teste"
      ],
      "metadata": {
        "id": "3n6KgGQH5hP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_preprocessed, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "mvDDcsTI5eVk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Tamanho do conjunto de treino: {X_train.shape}')\n",
        "print(f'Tamanho do conjunto de teste: {X_test.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANWQ5bzc5pvk",
        "outputId": "2b44acfd-875e-436c-b701-80b2f4c9ab38"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho do conjunto de treino: (67243, 208839)\n",
            "Tamanho do conjunto de teste: (16811, 208839)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O shape do conjunto ficou dividido do mesmo tamanho que o modelo de RL."
      ],
      "metadata": {
        "id": "NhP4j7JU5qS2"
      }
    }
  ]
}