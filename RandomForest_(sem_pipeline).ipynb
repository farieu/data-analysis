{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNS6tAFgN+cmWG5SrP3/wk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farieu/data-analysis/blob/OutrosModelos/RandomForest_(sem_pipeline).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treinamento com Random Forest"
      ],
      "metadata": {
        "id": "o387oci4k7IB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esse treinamento é uma nova versão do que estava commitado. A primeira versão do pipeline apresentava vários bugs, e ocasionava na elaboração de um dataset gigantesco, muito diferente do que o que usei para Regressão.\n",
        "\n",
        "---\n",
        "Essa nova versão utiliza o GoodReads Encoded, fruto da branch **SelecaoFeatures**, mesmo dataset que usei para treinar o modelo de Regressão."
      ],
      "metadata": {
        "id": "lakUFQXuWiN9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importação de bibliotecas e dataset"
      ],
      "metadata": {
        "id": "aZ-FPGTR97fV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ar8_3LN4lv5Z",
        "outputId": "1337cd52-7be7-4a39-89f7-9a296d2dd1ff"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4CRlq2Rgki2x"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import Binarizer, LabelEncoder, MultiLabelBinarizer\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/BackEnd/Treinamento/GoodReadsEncoded.csv')"
      ],
      "metadata": {
        "id": "Dz6vUN_TlyWh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Treinamento sem passar pelo Pipeline de Pré-Processamento"
      ],
      "metadata": {
        "id": "h7OEkQRNmtN_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com o dataset codificado, começo a preparar o treinamento:\n",
        "dividindo o conjunto em características (features), através\n",
        "\n",
        "1.   Dividindo o conjunto em X e y\n",
        "2.  **X**: características/variáveis independentes, que vão servir como entrada para o modelo.\n",
        "3. **Y**: variável dependente que o modelo está tentando prever, ou seja, a nota do livro.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tTSXOWmypzsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=['rating', 'desc'])\n",
        "y = df['rating']"
      ],
      "metadata": {
        "id": "kRUIlGCwnCN-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.columns)\n",
        "print(X.head(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVdsGBfUEDiF",
        "outputId": "627d6fd2-1025-4c0c-d40e-d61cdc36c5f8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['author', 'bookformat', 'pages', 'reviews', 'title', 'totalratings',\n",
            "       '10th Century', '11th Century', '12th Century', '13th Century',\n",
            "       ...\n",
            "       'Young Adult Paranormal', 'Young Adult Romance',\n",
            "       'Young Adult Science Fiction', 'Young Readers', 'Yuri', 'Zambia', 'Zen',\n",
            "       'Zimbabwe', 'Zombies', 'æ¼«ç”»'],\n",
            "      dtype='object', length=1185)\n",
            "   author  bookformat  pages  reviews  title  totalratings  10th Century  \\\n",
            "0   32032          56      0        5   8698            33             0   \n",
            "1    8446         100    576        6  21651            41             0   \n",
            "\n",
            "   11th Century  12th Century  13th Century  ...  Young Adult Paranormal  \\\n",
            "0             0             0             0  ...                       0   \n",
            "1             0             0             0  ...                       0   \n",
            "\n",
            "   Young Adult Romance  Young Adult Science Fiction  Young Readers  Yuri  \\\n",
            "0                    0                            0              0     0   \n",
            "1                    0                            0              0     0   \n",
            "\n",
            "   Zambia  Zen  Zimbabwe  Zombies  æ¼«ç”»  \n",
            "0       0    0         0        0       0  \n",
            "1       0    0         0        0       0  \n",
            "\n",
            "[2 rows x 1185 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)\n",
        "print(y.head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GT2pVNhCEEHQ",
        "outputId": "84d60bb8-8c8b-4ad7-b6ec-0cd82f88b6b7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        3.52\n",
            "1        4.51\n",
            "2        4.15\n",
            "3        3.83\n",
            "4        3.73\n",
            "         ... \n",
            "84049    3.77\n",
            "84050    3.97\n",
            "84051    4.27\n",
            "84052    3.63\n",
            "84053    3.83\n",
            "Name: rating, Length: 84054, dtype: float64\n",
            "0    3.52\n",
            "1    4.51\n",
            "2    4.15\n",
            "Name: rating, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conforme mostrado na Preparação do Modelo, precisamos binarizar as notas para treinamento.\n",
        "\n",
        "\n",
        "\n",
        "*   Avaliações de livros maior ou igual a 4 serão categorizadas como '1' (boa avaliação).\n",
        "*   Avaliações menores que 4 serão categorizadas como '0' (má avaliação)\n",
        "\n"
      ],
      "metadata": {
        "id": "NY49RTy9pqUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binarizer = Binarizer(threshold=3.5)\n",
        "y_binary = binarizer.fit_transform(y.values.reshape(-1, 1)).ravel()\n",
        "print(y_binary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wSq6vVZp9H5",
        "outputId": "b13c1df4-025b-4a9a-945e-ca2fc1c4817d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. ... 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora, precisamos separar os conjuntos de treino e de teste. Para a **Random Forest**, será divido em:\n",
        "\n",
        "1.   **80% para Treinamento**\n",
        "2.   **20% para Teste**"
      ],
      "metadata": {
        "id": "0qTAwUVErEfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "XPAM6sBFrDLw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instanciamento do Random Forest, treinamento e avaliação do modelo."
      ],
      "metadata": {
        "id": "r8kRiAys85VQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Avaliar o desempenho do modelo, relatório de classificação e matriz de confusão.\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Acurácia do modelo: {accuracy:.2f}\")\n",
        "print(\"\\nRelatório de Classificação:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"\\nMatriz de Confusão:\\n\", confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1i6j0El8tO6",
        "outputId": "0992272a-57bb-4685-e159-74b5dcaec956"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia do modelo: 0.88\n",
            "\n",
            "Relatório de Classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.63      0.12      0.21      2043\n",
            "         1.0       0.89      0.99      0.94     14768\n",
            "\n",
            "    accuracy                           0.88     16811\n",
            "   macro avg       0.76      0.56      0.57     16811\n",
            "weighted avg       0.86      0.88      0.85     16811\n",
            "\n",
            "\n",
            "Matriz de Confusão:\n",
            " [[  251  1792]\n",
            " [  148 14620]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O resultado do modelo Random Forest, quando comparado ao modelo de [Regressão Linear](https://github.com/farieu/data-analysis/blob/AvaliacaoModeloRL/AvaliacaoModeloRL.ipynb), apresenta resultados interessantes.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "De forma geral, o modelo apresenta alta acurácia, de 88%, mas as métricas para cada classe mostram um problema significativo na identificação de livros com má avaliação (classe 0).\n",
        "\n",
        "O recall da classe 0 é MUITO baixo, indicando que o modelo não consegue identificar a maioria de má avaliação, classificando-os erroneamente como \"boa avaliação\". Esse comportamento é evidênciado pela quantidade alta de **falsos positivos (1967)**, o que mostra um viés do modelo em favor da classe 1.\n"
      ],
      "metadata": {
        "id": "VdIsLu5sHVac"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entretanto, para a classe de boa avaliação, o modelo consegue identificar corretamente todas as instâncias, sem deixar nenhum livro bem avaliado passar despercebido. Isso também é perceptível pelo F1-Score de 94%.\n",
        "\n",
        "---\n",
        "\n",
        "O modelo demonstrou similaridade com o **Treinamento 4** de Regressão Logística, o que sugere um possível desbalanceamento das classes, sendo necessário ajustes futuros no modelo."
      ],
      "metadata": {
        "id": "GLXlMtzwIsGy"
      }
    }
  ]
}